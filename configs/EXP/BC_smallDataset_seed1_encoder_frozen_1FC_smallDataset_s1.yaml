####General Configuration Parameters####
SAVE_SCHEDULE: [1000] # The iterations where training checkpoints are going to be saved
NUMBER_OF_LOADING_WORKERS: 12   # Number of threads used in the data loader
MAGICAL_SEED: 1314

####Input related parameters####
# A dictionary with all the sensors that are going to be used as input
# this should match the train dataset
SENSORS:
  rgb_central: [3, 88, 200] # A RGB input sensor with three channels that is resized to 200x88
MEASUREMENTS:
  float_data: [31]  # Number of float data that must be read from the dataset
COMMANDS:
  directions: 4
BATCH_SIZE: 120
NUMBER_ITERATIONS: 1001
AFFORDANCES_TARGETS:
  classification: ['is_pedestrian_hazard', 'is_red_tl_hazard', 'is_vehicle_hazard']
  regression: ['relative_angle']  # From the float data, the ones that the network should estimate

INPUTS: ['forward_speed'] # From the float data, the ones that are input to the neural network
NUMBER_FRAMES_FUSION: 1  # Number of frames fused
NUMBER_IMAGES_SEQUENCE: 1  # Number of frames sent in sequence
SEQUENCE_STRIDE: 1  # Number of frames skipped when reading the data
AUGMENT_LATERAL_STEERINGS: 6  # Depending on this value there is a constant multiplying lateral steers
SPEED_FACTOR: 12.0  # The constant that is divides the speed_module in order to make it from 0-1
TRAIN_DATASET_NAME: 'small_dataset'  # The name of the training dataset used. Must be inside SRL_DATASET_PATH folder
AUGMENTATION: None  # The image augmentation applied on every input image
DATA_USED: 'central'  # The part of the data to be used
USE_NOISE_DATA: True  # If we use the noise data.
EXPERIENCE_FILE: ['$ACTIONDIR/carl/database/small_dataset.json']
#### Testing Related Parameters ####
TEST_SCHEDULE: [1000] # The iterations where training checkpoints are going to be saved
  # The frequency the model is actually tested.

#### Model Related Parameters ####
# Network Parameters #
MODEL_TYPE: 'separate-affordances' # The type of model. Defines which modules the model has.
MODEL_CONFIGURATION:  # Based on the MODEL_TYPE, we specify the structure
  affordances:
      number_of_classification: 3
      number_of_regression: 1

FREEZE_ENCODER: True
ENCODER_MODEL_TYPE: 'ETE'
ENCODER_MODEL_CONFIGURATION:   # We specify the structure of VAE model
  perception:  # The module that process the image input, it ouput the number of classes
    res:
      name: 'resnet34'
      num_classes: 512

  measurements:
    fc:
      neurons: [128, 128]
      dropouts: [0.0, 0.0]
  command:  # The module the process the command
    fc:  # Easy to configure fully connected layer
      neurons: [128, 128] # Each position add a new layer with the specified number of neurons
      dropouts: [0.0, 0.0]
  join:
    fc:
      neurons: [512]
      dropouts: [0.0]
  speed_branch:
    fc:
      neurons: [256, 256]
      dropouts: [0.0, 0.5]
  action:  # The output branches for the different possible directions ( Straight, Left, Right, None)
    fc:
      neurons: [256, 256]
      dropouts: [0.0, 0.5]

# Optimizer Parameters #
# For now we use only use adam
LEARNING_RATE: 0.0002  # First learning rate
LEARNING_RATE_DECAY_INTERVAL: 75000 # Number of iterations where the learning rate is reduced
LEARNING_RATE_THRESHOLD: 5000 # Number of iterations without going down to reduce learning rate
LEARNING_RATE_DECAY_LEVEL: 0.1 # Th factor of reduction applied to the learning rate

# Loss Parameters #
AFFORDANCES_CLASS_WEIGHT: [[0.06, 0.94], [0.16, 0.84], [0.16, 0.84]]  # The classification label (True and False) occurence in the training dataset (order should match)
AFFORDANCES_VARIABLE_WEIGHT: [2.00]     # how much each of the outputs specified on TARGETS are weighted for learning.

#### Simulation Related Parameters ####
IMAGE_CUT: [65, 460]  # How you should cut the input image that is received from the server
USE_ORACLE: False
USE_FULL_ORACLE: False
AVOID_STOPPING: False
